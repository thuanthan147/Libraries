{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_page_table:\n",
    "# Crawling data info in a webpage\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        # Initialize \n",
    "        self.url = url\n",
    "        html_doc = requests.get(self.url)\n",
    "        self.soup = bs(html_doc.text, 'lxml')\n",
    "        \n",
    "    def extract_table(self, flag=None):\n",
    "        \"\"\"\n",
    "        Return a table in the page\n",
    "        flag: a list contain 2 element: attribute and value\n",
    "        \n",
    "        Return:\n",
    "            table: list\n",
    "            table from the url with given flag\n",
    "        \"\"\"\n",
    "        return_list = []\n",
    "        \n",
    "        if flag != None:\n",
    "            try:\n",
    "                table = self.soup.find('table',{flag[0]: flag[1]})\n",
    "            except:\n",
    "                print(\"Can't find table with given attribute\")\n",
    "                return []\n",
    "        else:\n",
    "            table = self.soup.findAll('table')\n",
    "            if not table:\n",
    "                print(\"Page doesn't have any table!\")\n",
    "                return []\n",
    "        \n",
    "        if str(type(table)) == \"<class 'bs4.element.Tag'>\":\n",
    "            temp_table = []\n",
    "            rows = table.find_all(\"tr\")\n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                cols = [element.text.strip() for element in cols]  \n",
    "                temp_table.append(cols)\n",
    "            return_list.append(temp_table)\n",
    "        else:\n",
    "            for tabl in table:\n",
    "                temp_table = []\n",
    "                rows = tabl.find_all(\"tr\")\n",
    "                for row in rows:\n",
    "                    cols = row.find_all('td')\n",
    "                    cols = [element.text.strip() for element in cols]  \n",
    "                    temp_table.append(cols)\n",
    "                return_list.append(temp_table)\n",
    "        return return_list\n",
    "    \n",
    "    def extract_page_table(self, write_down = False, flag=None):\n",
    "        \"\"\" Extract all tables in a webpage, return list or write to csv\n",
    "            write_down: bool\n",
    "                if True, write to csv file\n",
    "                else return a list\n",
    "            flag: list of lists, which contain 2 element\n",
    "                find all table contraining given attribute and value\n",
    "        \"\"\"\n",
    "        final_table = []\n",
    "        if flag != None:\n",
    "            for pair in flag:\n",
    "                table = self.extract_table(pair)\n",
    "                if table:\n",
    "                    count = 0\n",
    "                    for tab in table:\n",
    "                        count += 1\n",
    "                        if write_down:\n",
    "                            df = pd.DataFrame(tab)\n",
    "                            df.to_csv(str(count) + \".csv\")\n",
    "                        else:\n",
    "                            final_table.append(tab)\n",
    "        else:\n",
    "            table = self.extract_table(flag)\n",
    "            if table:\n",
    "                count = 0\n",
    "                for tab in table:\n",
    "                    count += 1\n",
    "                    if write_down:\n",
    "                        df = pd.DataFrame(tab)\n",
    "                        df.to_csv(str(count) + \".csv\")\n",
    "                    else:\n",
    "                        final_table.append(tab)\n",
    "        if not write_down:\n",
    "            return final_table\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparser.ArgumentParser()\n",
    "parser.add_argument(\"url\",help=\"Url you want to get the tables\", type=str)\n",
    "parser.add_argument(\"write_down\",help=\"True: write down to file\", type=bool)\n",
    "parser.add_argument(\"flag\",help=\"List of pairs of attribute and value of a specific table, ex: \\[\\['class','something'\\]\\], type=str)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = \"[['class','str']]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
